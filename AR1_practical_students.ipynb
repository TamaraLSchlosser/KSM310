{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "d12e851d-d9e3-441e-9666-75506de8d024",
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport numpy as np\nimport xarray as xr\nfrom datetime import datetime\nfrom statsmodels.tsa.ar_model import AutoReg\nfrom scipy.ndimage import uniform_filter1d,gaussian_filter1d",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "Matplotlib is building the font cache; this may take a moment.\n"
        }
      ],
      "execution_count": 2
    },
    {
      "id": "3629a713-7b14-4fd9-981d-363191b93016",
      "cell_type": "code",
      "source": "#%% Read SST and pick out locations of interest\n# Open the netCDF file and read the SST data\nfile_path = \"sst.mnmean.nc\"  # Uploaded into Data folder in the File Browser window\ndataset = xr.open_dataset(file_path,decode_times=True)\n\n# Extract latitude, longitude, and SST variables\nlats = dataset['lat'].values\nlons = dataset['lon'].values\nsst = dataset['sst'].values # time, lat, lon\n\ntime = dataset['time'].values\n\n# Debug: Check the converted time\nprint(\"Converted time example:\", time[:5])\n\n# Close the dataset\ndataset.close()\n\n# function to find closest grid cell\ndef find_index(x,y):\n    lat_idx = np.abs(lats - y).argmin()  # Find index of nearest latitude\n    lon_idx = np.abs(lons - x).argmin()  # Find index of nearest longitude\n    return lon_idx, lat_idx\n\n# testing it works\nthisLong, thisLat = find_index(16,5)\nprint([thisLong, thisLat])\nprint(lons[thisLong])\nprint(lats[thisLat])\n\n# Define the locations of interest (latitude, longitude)\nlocations = [\n    {\"name\": \"Byron Bay\", \"lat\": -28.7, \"lon\": 156},\n    {\"name\": \"Perth\", \"lat\": -32, \"lon\": 115},\n]\nnloc=len(locations)\n\nsst_values = np.full((nloc, len(time)), np.nan)\nfor ii, loc in enumerate(locations):  # Enumerate provides the index (i) and the location (loc)\n    lon_idx, lat_idx = find_index(loc[\"lon\"],loc[\"lat\"])\n    sst_values[ii, :] = np.squeeze(sst[:, lat_idx, lon_idx])  # Assign the time series for this location, and squeeze to reduce dimensions\n\n# focus on last 30 years\ntind=time>=np.datetime64(\"1994-01-01\")\nyear=(time[tind]-np.min(time[tind])).astype('timedelta64[D]').astype('float32') / 365.25\nsst_values=sst_values[:,tind]\ntime=time[tind]\n\n# smooth or filter out seasonal variability\n# smooth via a 12-month running mean\nsst_smooth= uniform_filter1d(sst_values, size=12, axis=1,mode='nearest')\n# also try low-pass filter.\nsst_lowpass=gaussian_filter1d(sst_values, sigma=10, axis=1)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'ValueError'>",
          "evalue": "found the following matches with the input file in xarray's IO backends: ['netcdf4', 'h5netcdf']. But their dependencies may not be installed, see:\nhttps://docs.xarray.dev/en/stable/user-guide/io.html \nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#%% Read SST and pick out locations of interest\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Open the netCDF file and read the SST data\u001b[39;00m\n\u001b[1;32m      3\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msst.mnmean.nc\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Uploaded into Data folder in the File Browser window\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecode_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Extract latitude, longitude, and SST variables\u001b[39;00m\n\u001b[1;32m      7\u001b[0m lats \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/xarray/backends/api.py:651\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(backend_kwargs)\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 651\u001b[0m     engine \u001b[38;5;241m=\u001b[39m \u001b[43mplugins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguess_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_array_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    654\u001b[0m     from_array_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/xarray/backends/plugins.py:194\u001b[0m, in \u001b[0;36mguess_engine\u001b[0;34m(store_spec)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound the following matches with the input file in xarray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms IO \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackends: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompatible_engines\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. But their dependencies may not be installed, see:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.xarray.dev/en/stable/user-guide/io.html \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    192\u001b[0m     )\n\u001b[0;32m--> 194\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n",
            "\u001b[0;31mValueError\u001b[0m: found the following matches with the input file in xarray's IO backends: ['netcdf4', 'h5netcdf']. But their dependencies may not be installed, see:\nhttps://docs.xarray.dev/en/stable/user-guide/io.html \nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 4
    },
    {
      "id": "528a7541-9d7c-4b9a-924c-e14967c8aa4c",
      "cell_type": "code",
      "source": "#%% for seminar\nplt.figure(figsize=(8,3))\nplt.plot(time, sst_values[0,:], label=\"raw\",linewidth=2)\nplt.plot(time, sst_smooth[0,:], label=\"smoothed\",linewidth=4)\nplt.plot(time, sst_lowpass[0,:], label=\"filter\",linewidth=4)\nplt.legend()\nplt.xlabel('Year')\nplt.ylabel('Sea Surface Temperature (°C)')\nplt.tight_layout()\nplt.xlim(time[0], time[-1])\nplt.savefig(\"Byron_SST.jpg\", dpi=600, quality=95, bbox_inches='tight')\n\n# I like the filtered result so I'll use that",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4619267f-e021-49de-834f-08eb4ba88d44",
      "cell_type": "code",
      "source": "#%% Plot the SST values for the locations\n# Define the x-axis limits (use datetime objects for time)\nstart_date = datetime(1992, 1, 1)\nend_date = datetime(2022, 1, 1)\n\nplt.figure(figsize=(6, 4))\nfor ii, loc in enumerate(locations):\n    plt.plot(time, sst_values[ii, :], label=loc[\"name\"])  # Plot SST for each location\n\n# Set x-axis limits\nplt.xlim(start_date, end_date)\n\nplt.title(\"Sea Surface Temperature (SST) at Selected Locations\")\nplt.ylabel(\"SST (°C)\")\nplt.xlabel(\"year\")\n\n# Rotate date labels for better visibility\nplt.gcf().autofmt_xdate()\n\n#plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\nplt.legend(title=\"Locations\",loc=\"upper left\", fontsize=10)\nplt.grid(True)\nplt.tight_layout()\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "18dd11ef-9a22-44f6-b27e-82dec257dc79",
      "cell_type": "code",
      "source": "#%% Compute the long-term trend over last 30 years\ntrends = np.zeros(nloc)\nfitted = np.full((nloc,len(year)),np.nan)\nfor ii in range(nloc):\n    trend = np.polyfit(year, sst_lowpass[ii,:], 1)  # Linear trend (slope, intercept)\n    trends[ii]=trend[0] # deg C/year\n    fitted[ii,:]=np.polyval(trend, year)\n\n# Output trend values\nfor ii, trends in enumerate(trends):\n    print(f\"Location {ii+1}: 30-year trend = {trends}\")\n\n# plot trend lines\nplt.figure(figsize=(6, 4))\nfor ii, loc in enumerate(locations):\n    plt.plot(time, sst_values[ii, :], label=loc[\"name\"])  # Plot SST for each location\n    plt.plot(time,fitted[ii,:],'--')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "654a9da8-fef0-4633-993c-5705f829f6b9",
      "cell_type": "code",
      "source": "#%% thermal stress\nthermal_stress_temp = np.percentile(sst_values, 95,axis=1) # SST threshold for thermal stress\n\nplt.figure(figsize=(6,3))\nfor ii,loc in enumerate(locations):\n    plt.plot(time, sst_values[ii,:], label=loc[\"name\"])\n    # now add a red cross for thermal stress events\n    stress_ind=sst_values[ii,:]>thermal_stress_temp[ii]\n    plt.scatter(time[stress_ind],sst_values[ii,stress_ind],marker='x',c='red',label=\"stress\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "214e6a76-d2b2-44cd-8201-73475c44a5ed",
      "cell_type": "code",
      "source": "#%% Fitting Auto-Regressive (AR1) model to SST data\n# generate the future 10 years time variable\nyear_diff_median = np.median(np.diff(year))\nn10=int(np.round(10/year_diff_median))\ntime_diff_median = np.median(np.diff(time))\nfuture10 = np.arange(time[-1]+time_diff_median, time[-1]+time_diff_median*(n10+1),time_diff_median)\n\n# Fit the AR1 model and predict for the next n10 years\npredictions1 = np.full((nloc,n10),np.nan)\nar1_coefficients = []\n\n# Let's also save xi so we can see how the 'forcing' impacts our prediction\nrng = np.random.default_rng()  # Optional: set seed for reproducibility seed=42\nincrease_noise=2 # feel free to change this if you want more 'oscillatory' results\nxi=np.full((nloc,n10),np.nan) # our noise/forcing\n\nfor ii in range(sst_values.shape[0]):\n    # fit easing least-squares\n    model = AutoReg(sst_lowpass[ii,:], lags=1)\n    model_fitted = model.fit()\n    \n    intercept = model_fitted.params[0]\n    alpha = model_fitted.params[1]  # AR1 coefficient\n    residual_std = np.std(model_fitted.resid)# residual standard deviation, used to scale noise/forcing/xi\n    \n    # Initialize prediction array\n    pred = np.zeros(n10)\n    # define our xi or forcing\n    xi[ii,:]=residual_std * rng.normal(size=n10) * increase_noise\n    # find first forecasted value\n    pred[0] = alpha * sst_lowpass[ii, -1] + intercept + xi[ii,0]\n\n    # forecast next 10 years\n    for tt in range(1, n10):\n        pred[tt] = alpha * pred[tt-1] + intercept + xi[ii,tt-1]\n\n    predictions1[ii, :] = pred.copy()\n    ar1_coefficients.append(model_fitted.params[1])  # AR1 coefficient is the lag parameter\n\n# Output AR1 coefficients\nfor i, coeff in enumerate(ar1_coefficients):\n    print(f\"Location {i+1}: AR1 Coefficient = {coeff}\")\n\n# Plot the predictions\nplt.figure(figsize=(8, 3))\nfor ii in range(sst_values.shape[0]):\n    plt.plot(time, sst_lowpass[ii,:], label=f\"Location {ii+1}\")\n    plt.plot(future10, predictions1[ii,:], label=f\"Prediction AR1 {ii+1}\", linestyle='--')\n    ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "63c4e142-8df4-4c99-976a-346c9855ec33",
      "cell_type": "code",
      "source": "#%% What if we used a higher-order AR model? Like n10 order?\npredictions10y = np.full((3,n10),np.nan)\nalphas = np.full((3,n10),np.nan)\n\nfor ii in range(sst_values.shape[0]):\n    model = AutoReg(sst_lowpass[ii,:], lags=n10)\n    model_fitted = model.fit()\n    prediction = model_fitted.predict(start=len(time),end=len(time)+n10-1)  # Predict for the next 10 years\n    predictions10y[ii,:]=prediction\n    alphas[ii,:] = model_fitted.params[1:] \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'np' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#%% What if we used a higher-order AR model? Like n10 order?\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predictions10y \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mfull((\u001b[38;5;241m3\u001b[39m,n10),np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m      3\u001b[0m alphas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull((\u001b[38;5;241m3\u001b[39m,n10),np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(sst_values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 1
    }
  ]
}