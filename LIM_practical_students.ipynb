{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "dbc50285-c8a8-411c-a55d-a6e6b8539753",
      "cell_type": "code",
      "source": "\"\"\"\nWritten by T Schlosser and Y Wang\n\n@author: tamaras9\n\"\"\"\n\nfrom IPython import get_ipython\n# Clear all variables in Spyder's Variable Explorer\nget_ipython().run_line_magic('reset', '-f')\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport xarray as xr\nfrom scipy.signal import detrend\nimport pandas as pd\nfrom scipy.ndimage import uniform_filter1d\nfrom scipy.linalg import logm, pinv ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3952558b-e398-43de-acb1-09a37ee5719e",
      "cell_type": "code",
      "source": "#%% Data prep: Open SST data, find annual mean, then detrend data\n# Step 1: Open the netCDF file and read the SST data\nfile_path = \"sst.mnmean.nc\"  # Uploaded into Data folder in the File Browser window\ndataset = xr.open_dataset(file_path,decode_times=True)\n\n# Step 2: Extract latitude, longitude, and SST variables\nlats = dataset['lat'].values\nlons = dataset['lon'].values\nsst = dataset['sst'].values # time, lat, lon\nsst[sst<=-2]=np.NaN\n\ntime = dataset['time'].values\n\n# Close the dataset\ndataset.close()\n\n# smooth via a 3-month running mean\nsst_sm = uniform_filter1d(sst, size=3, axis=0, mode='nearest')\n\n# Remove climatology (i.e., monthly average)\nsst_anom=np.full_like(sst, np.nan)\nfor mm in range(12):\n    climatology = np.nanmean(sst_sm[mm::12, :, :], axis=0)  # Compute climatology for month mm\n    sst_anom[mm::12,:,:]=sst_sm[mm::12,:,:]-climatology\n\n# now need to decrease run time by decreasing the size of our sst array\n# use only last 70 years to match with Nino3 index\ntind=time>=np.datetime64(\"1954-01-01\")\nsst_anom=sst_anom[tind,:,:]\nsst=sst[tind,:,:]\ntime=time[tind]\n\n# limit to +-60 lat\nyind=np.abs(lats)<=60\nlats=lats[yind]\nsst_anom=sst_anom[:,yind,:]\n\n# example code for plotting SST anomalies in one year\nplt.figure(figsize=(8, 6))\nplt.pcolor(lons,lats,sst_anom[0,:,:])\nplt.colorbar(label=\"SST Anomaly - 1950\")\nplt.xlabel(\"longitude (°E)\")\nplt.ylabel(\"latitude (°N)\")\nplt.show()   \n\n# we have now smoothed and demeaned the SST data\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "45c41e55-8dae-4da7-b63f-8c76d833fa8b",
      "cell_type": "code",
      "source": "#%% Next vectorize each time step \n# I need the array to have dimensions [time x space] instead of [time x lat x lon]\ntmp=sst_anom # [time x lats x lons]\n# don't include grid cells with NaNs or consistently very small SST anomalies\ntmp[np.isnan(tmp)]=0\ncount = np.sum(np.abs(tmp) < 1e-2, axis=0)\nbad_ind=count>5*12 # if more than 5 years with \"bad\" data, then we want to omit\ntmp=tmp[:,~bad_ind]\n\nsst_vect = np.full((len(time),np.size(tmp, axis=1)), np.nan) # time x global cells\nfor tt in range(len(time)):\n    # take a time slice\n    tmp=sst_anom[tt,:,:]\n    # remove nans/very small points\n    tmp=tmp[~bad_ind]\n    # assign\n    sst_vect[tt,:]=tmp.copy()\n\nplt.figure(figsize=(8, 6))\nplt.pcolor(time[:12],range(sst_vect.shape[1]),sst_vect[:12,:].T)\n\n# Rotate date labels for better visibility\nplt.gcf().autofmt_xdate()\n\nplt.colorbar(label=\"SST Anomaly (°C)\")\nplt.xlabel(\"1st 12 time steps\")\nplt.ylabel(\"global cells\")\nplt.show()\n\n# next linearly detrend the data so that the mean is around 0 for all decades\nsst_detrend=np.full_like(sst_vect, np.nan)\nsst_trend=np.full_like(sst_vect, np.nan)\nfor ii in range(sst_vect.shape[1]):    \n    # Apply detrending while ignoring NaNs\n    sst_detrend[:,ii]= detrend(sst_vect[:,ii], type='linear')\n    sst_trend[:,ii]=sst_vect[:,ii]-sst_detrend[:,ii]\n\n# example code for plotting detrended SST anomalies in one grid cell\nplt.figure(figsize=(8, 6))\nplt.plot(time,sst_vect[:,0],color=\"blue\",label=\"raw\")\nplt.plot(time,sst_detrend[:,0],color=\"red\",label=\"detrended\")\nplt.plot(time,sst_trend[:,0],color=\"black\",label=\"trend\")\nplt.hlines(0,time[0],time[-1],color='k',linestyles='--')\nplt.legend()\nplt.xlabel(\"date\")\nplt.ylabel(\"SST Anomaly (°C)\")\nplt.show()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3ccbd4c4-b310-44e6-9a6b-7f94fb190efe",
      "cell_type": "code",
      "source": "#%% Apply latitude weights to SST anomalies for EOF analysis then normalise\n\n# Prepare array with cos(latitude) values. sst_detrend will be multiplied by cos(latitude) before EOF calculation\ncoslat = np.cos(np.deg2rad(lats))\nwgts = coslat[..., np.newaxis]\ncossF = np.zeros_like(sst_anom)\n# Broadcast wgts to all rows of cossF\ncossF[:] = wgts\n\n# Reshape array to (time, space)\ncoss_a = cossF.reshape(len(time),(len(lats) * len(lons)))\nbad_ind_vect = bad_ind.reshape((len(lats) * len(lons)))\n# Remove missing values from the design matrix.\ncoss_a = coss_a[:,~bad_ind_vect]\n\n# Multiply by cosine of latitude\nsst_anom_primed=sst_detrend*coss_a\n\n# Normalise each field (this is needed when more than one variable is used)\n# Compute the variance at each grid point, take the average, take the square root\nvart = np.nanvar(sst_anom_primed,axis=0)\nAA_sst=np.sqrt(np.nanmean(vart))\n\n# Normalise\nsst_anom_primed=sst_anom_primed/AA_sst",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2cd26dc7-cf60-4990-9b4b-2710f5d3aca3",
      "cell_type": "code",
      "source": "#%% Do EOF analysis for SST anomalies\n\n# Perform EOF analysis: Compute EOFs, PCs, and explained variance\nn_modes=5 # number of EOFs, adjustable\n\n# Compute EOFs of SST\n_, S1, C1 = np.linalg.svd(sst_anom_primed, full_matrices=False)\n\nS1 = np.diag(S1)  # Convert singular values to a diagonal matrix\nfve1 = np.round(np.diag(S1)**2/np.nansum(np.diag(S1)**2),2) # Fraction of variance explained\nPCs = sst_anom_primed @ (C1.T) # Compute PCs by projecting  \n\n# Retain the first n_modes PCs SST data on EOFs\nPCs=PCs[:,:n_modes] # Chosen leading PCs, i.e., timeseries\nEOFs=C1[:n_modes,:] # Chosen leading EOFs, i.e., spatial pattern\n#(np.sum(fve1[:n_modes])) # Variance explained by n_modes, i.e., eigenvalues\n\nscale=np.max(np.abs(EOFs[0,:]))\n\nplt.figure(figsize=(8, 6))\nplt.plot(time,PCs*scale)\nplt.xlabel(\"date\")\nplt.ylabel(\"PCs (°C)\")\nplt.show()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d4363f80-bdb3-4fb6-aea4-33a6501ea573",
      "cell_type": "code",
      "source": "#%% Retranslate vector [time x global cells] data into spatial map [time x lats x lons]\n\nEOFs_world=np.full((n_modes,len(lats),len(lons)), np.nan)\nclim=np.full((n_modes), np.nan) # colour limits when plotting\nfor ii in range(n_modes):\n    tmp=np.full((len(lats),len(lons)), np.nan)\n    tmp[~bad_ind]=EOFs[ii,:]\n    EOFs_world[ii,:,:]=tmp\n    # estimate good plotting colour limits\n    clim[ii]=np.percentile(np.abs(EOFs[ii,:]),100)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "7f9bb77f-0d5b-46b0-b301-9f98f3115299",
      "cell_type": "code",
      "source": "#%% Plot all EOFs and PCs. \n# for plotting purposes, we will set the EOF amplitudes to ~=1 and modify PC accordingly\n\nfor mode in range(n_modes):\n    fig, ax = plt.subplots(2, 1, figsize=(16, 8), gridspec_kw={'height_ratios': [2, 1]}, constrained_layout=True)\n\n    # --- Top Plot: Spatial EOF ---\n    levels = np.linspace(-1, 1, 53)\n    eof_data = EOFs_world[mode, :, :]\n    contour = ax[0].contourf(lons, lats, eof_data/scale, levels=levels, cmap='RdBu_r', vmin=-1, vmax=1)\n\n    cbar = plt.colorbar(contour, ax=ax[0], orientation='vertical', fraction=0.05, pad=0.02)\n    cbar.set_label(f\"EOF{mode+1} Amplitude (unitless)\", fontsize=14)\n\n    ax[0].set_xlabel(\"Longitude (°E)\", fontsize=12)\n    ax[0].set_ylabel(\"Latitude (°N)\", fontsize=12)\n    ax[0].set_title(f\"Spatial EOF-{mode+1}: {fve1[mode]*100}% variance\", fontsize=12, fontweight=\"bold\")\n    ax[0].tick_params(axis='both', labelsize=11)\n\n    # --- Bottom Plot: PC Time Series ---\n    pc = PCs[:, mode]\n    ax[1].plot(time, pc*scale, color='k', linewidth=2)\n    ax[1].plot(time, np.zeros(len(time)), color='k', linestyle='--', linewidth=1)\n\n    # Shading: Red for positive, blue for negative\n    ax[1].fill_between(time, pc*scale, 0, where=(pc > 0), color='red', alpha=0.3)\n    ax[1].fill_between(time, pc*scale, 0, where=(pc < 0), color='blue', alpha=0.3)\n\n    ax[1].set_xlabel(\"date\", fontsize=12)\n    ax[1].set_ylabel(\"PC Amplitude (°C)\", fontsize=12)\n    ax[1].set_title(f\"PC-{mode+1}\", fontsize=12, fontweight=\"bold\")\n    ax[1].tick_params(axis='both', labelsize=11)\n    ax[1].grid(True, linestyle=\"--\", linewidth=0.5)\n    ax[1].set_xlim(time[0], time[-1])\n\n    # Save each figure\n    plt.savefig(f\"EOF{mode+1}_PC.jpg\", dpi=600, bbox_inches='tight')\n    #plt.close()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d14080ba-d705-48a9-b836-447ed8f1a471",
      "cell_type": "code",
      "source": "#%% LIM computation\n\n# This option allows to compute a LIM operator over a subperiod, and make a prediction of a following period if desired\ntime_max=1980\ntime_LIM = np.datetime64(f\"{time_max}-01-01\")\nind_timel = time < time_LIM\ntimel = time[ind_timel]\nneof = n_modes\nntm = len(timel)\n\n# Define state vector to compute the LIM \nPC1 = PCs[ind_timel,:]\n# subtract time mean of each PC; needed when using a sub-period\nPC1 = PC1 - np.nanmean(PC1,axis=0)\n\n# Calculate 0-lag covariance\nC0 = ((PC1.T) @ PC1) / (PC1.shape[0]-1)\n\n# Choose training lag (months)\ntau0 = 1   # Training lag; needed to compute lag-covariance matrix\n\nX0 = PC1[:-tau0,:] - np.nanmean(PC1[:-tau0,:],axis=0)\nXtau = PC1[tau0:,:] - np.nanmean(PC1[tau0:,:],axis=0)\n\n# Calculate tau0-lag covariance, here tau0=1\nCtau = ((Xtau.T) @ X0)/ (X0.shape[0]-1)\n\n# Compute LIM operators\nG0 = Ctau @ pinv(C0)\nL0 = logm(G0)/tau0 # our L linear operator\nL0 = np.real(L0)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "67d9d76f-7cff-48b9-bae5-12e576b9a0ea",
      "cell_type": "code",
      "source": "#%% Q1: Contrast modes with Nino3: https://psl.noaa.gov/data/timeseries/monthly/NINO3/\n# Nino3: Central Tropical Pacific SST (5N-5S;150W-90W). Calculated from the NOAA ERSST V5.\ncentral_yind=(lats>=-5) & (lats<=5)\ncentral_xind=(lons>=210) & (lons<=270) # 150W=-150+360=210\n# Use np.ix_ to create an indexer for the 2D region (latitude, longitude)\nlat_ind, lon_ind = np.ix_(central_yind, central_xind)\n\n# Load CSV while skipping the first row\nfile_path = \"Nino3_index.csv\"\nNino3 = pd.read_csv(file_path, skiprows=1,delim_whitespace=True, header=None)\nNino3 = Nino3.apply(pd.to_numeric, errors=\"coerce\")  # Convert everything possible to numbers\n\n# Rename columns (assuming the first column is Year, followed by 12 months)\nNino3.columns = [\"Year\", \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n\n# don't need last 3 rows\nNino3 = Nino3.drop(index=[78,79,80], axis=0)\n\n# Convert \"Year\" column to integers\nNino3[\"Year\"] = Nino3[\"Year\"].astype(int)\n# ERA5 data stops in 2023 and starts in 1954\nNino3 = Nino3[Nino3[\"Year\"] <= 2023]\nNino3 = Nino3[Nino3[\"Year\"] >= 1954]\nNino3 = Nino3.reset_index(drop=True)\n\n# bad data was set to -99.99\nNino3.loc[:, Nino3.columns != \"Year\"] = Nino3.loc[:, Nino3.columns != \"Year\"].where(Nino3.loc[:, Nino3.columns != \"Year\"] >= -90, np.nan)\n\nNino3_index=Nino3.iloc[:,1:].to_numpy()\nNino3_index= Nino3_index.flatten()\n\ntime_Nino=time[0:len(Nino3_index)]\n\n# plot Nino3 index\nfig, (ax1,ax2) = plt.subplots(2, sharex=True, figsize=(8, 6))\nax1.plot(time_Nino,Nino3_index)\nax1.grid()\nax1.set(ylabel=\"Nino3 index\")\n\n# correlate Nino3 indices with mode amplitudes\nspatial_map=np.full((len(time),len(lats[central_yind]),len(lons[central_xind])),np.nan)\nCTP_ampl=np.full((len(time),n_modes),np.nan)\nR=np.full(n_modes,np.nan)\n\n# consider whether all modes are necessary in plot. Perhaps reduce to first few?\nfor ii in range(n_modes):\n    sign=np.sign(np.mean(EOFs_world[ii,lat_ind, lon_ind]))\n    Rtmp=np.corrcoef(PCs[0:len(Nino3_index),ii]*sign,Nino3_index)\n    R[ii]=Rtmp[0,1]# correlation coefficient\n    \n    # now plot\n    ax2.plot(time_Nino,PCs[0:len(Nino3_index),ii]*scale*sign,label=f\"M{ii + 1}, R={R[ii]:.2f}\")\n    \nplt.legend()\nax2.grid()\nax2.set_ylabel(\"PC (°C) * sign of EOF in CTP\")\n\nplt.savefig(\"Nino3_SST_modes.jpg\", dpi=600, bbox_inches='tight')\n\nprint(\"Correlation coefficient with Nino3 Index:\",np.round(R,2))\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5bd139ec-aeec-4cd1-a96f-b32b8d7ccca2",
      "cell_type": "code",
      "source": "#%% Q2: SST anomalies vs Nino3\nnloc=3\nlocations = [\n    {\"name\": \"Ningaloo\", \"lat\": -22.6, \"lon\": 112},\n    {\"name\": \"GBR\", \"lat\": -18, \"lon\": 150},\n    {\"name\": \"Galapogas\", \"lat\": -0, \"lon\": -90+360},\n]\n# function to find closest grid cell\ndef find_index(x,y):\n    lat_idx = np.abs(lats - y).argmin()  # Find index of nearest latitude\n    lon_idx = np.abs(lons - x).argmin()  # Find index of nearest longitude\n    return lon_idx, lat_idx\n\nsst_values = np.full((nloc, len(time)), np.nan)\nsst_anom_loc= np.full((nloc, len(time)), np.nan)\nfor ii, loc in enumerate(locations):  # Enumerate provides the index (i) and the location (loc)\n    lon_idx, lat_idx = find_index(loc[\"lon\"],loc[\"lat\"])\n    sst_values[ii, :] = np.squeeze(sst[:, lat_idx, lon_idx])  # Assign the time series for this location, and squeeze to reduce dimensions\n    sst_anom_loc[ii, :] = np.squeeze(sst_anom[:, lat_idx, lon_idx])\n\nfig, axes = plt.subplots(len(locations), sharex=True, figsize=(10, 6))\n\nfor ii, loc in enumerate(locations):\n    ax1 = axes[ii]                        # Left y-axis (SST anomaly)\n    ax2 = ax1.twinx()                     # Right y-axis (Nino3 index)\n    \n    # Plot SST anomaly\n    ax1.plot(time, sst_anom_loc[ii, :], label=f\"SST Anomaly - {loc['name']}\", color='tab:blue')\n    ax1.hlines(0,time[0],time[-1],color=\"black\",linestyle=\"--\")\n    ax1.set_ylabel(\"SST Anom (°C)\", color='tab:blue')\n    ax1.tick_params(axis='y', labelcolor='tab:blue')\n    ymin, ymax = ax1.get_ylim()\n    ymax=np.max(np.abs([ymin,ymax]))\n    ax1.set_ylim(-ymax,ymax)\n    ax1.set_xlim(time[0],time[-1])\n    \n    # Plot Nino3 index\n    ax2.plot(time_Nino, Nino3_index, label=\"Nino3\", color='tab:red')\n    ax2.set_ylabel(\"Nino3 Index\", color='tab:red')\n    ax2.tick_params(axis='y', labelcolor='tab:red')\n    ymin, ymax = ax2.get_ylim()\n    ymax=np.max(np.abs([ymin,ymax]))\n    ax2.set_ylim(-ymax,ymax)\n    ax2.set_xlim(time[0],time[-1])\n    \n    # Title for each subplot\n    ax1.set_title(f\"SST Anomaly at {loc['name']} vs Nino3\")\n\n# Shared x-label\nplt.xlabel(\"time\")\nplt.tight_layout()\nplt.savefig(\"SSTA_vs_Nino3_3locations.jpg\", dpi=600, bbox_inches='tight')\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "700f9487-857f-44c0-93e1-ed8ac1f86dbb",
      "cell_type": "code",
      "source": "#%% Q3: finding which modes contributed to the warmest SST anomalies\n\nfig, axes = plt.subplots(len(locations), sharex=True, figsize=(10, 6))\n\n# Check EOF*_PC.jpg then update accordingly. The dimensions are location x mode number\nPC_sign=np.array([[1, 1, 1],\n                    [1, 1, 1],\n                    [1, 1, 1]])\n\nfor ii, loc in enumerate(locations):\n    ax1 = axes[ii]                        # Left y-axis (SST anomaly)\n    ax2 = ax1.twinx()                     # Right y-axis (Nino3 index)\n    \n    # Plot SST anomaly\n    ax1.plot(time, sst_anom_loc[ii, :], label=f\"SST Anomaly - {loc['name']}\", color='tab:blue')\n    ax1.hlines(0,time[0],time[-1],color=\"black\",linestyle=\"--\")\n    ax1.set_ylabel(\"SST Anom (°C)\", color='tab:blue')\n    ax1.tick_params(axis='y', labelcolor='tab:blue')\n    ymin, ymax = ax1.get_ylim()\n    ymax=np.max(np.abs([ymin,ymax]))\n    ax1.set_ylim(-ymax,ymax)\n    ax1.set_xlim(time[0],time[-1])\n    \n    # Plot Nino3 index\n    ax2.plot(time, PCs[:,0]*scale*PC_sign[ii,0], color='tab:red',label=\"mode-1\")\n    ax2.plot(time, PCs[:,1]*scale*PC_sign[ii,0], color='tab:green',label=\"mode-2\")\n    ax2.plot(time, PCs[:,2]*scale*PC_sign[ii,0], color='tab:purple',label=\"mode-3\")\n    ax2.set_ylabel(\"PCs (°C)\", color='black')\n    ax2.tick_params(axis='y', labelcolor='black')\n    ax2.legend(loc=\"upper left\")\n    ymin, ymax = ax2.get_ylim()\n    ymax=np.max(np.abs([ymin,ymax]))\n    ax2.set_ylim(-ymax,ymax)\n    ax2.set_xlim(time[0],time[-1])\n    \n    # Title for each subplot\n    ax1.set_title(f\"SST Anomaly at {loc['name']} vs PC-1 \")\n\n# Shared x-label\nplt.xlabel(\"time\")\nplt.tight_layout()\nplt.savefig(\"SSTA_vs_3PCs_3locations.jpg\", dpi=600, bbox_inches='tight')\nplt.show()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "eb9c894b-7fd9-4782-9d37-0f10d25f3aae",
      "cell_type": "code",
      "source": "#%% Q4: LIM Eigenanalysis\n# Eigenvalue analysis of L0\nlambda_vals, lambda_vecs = np.linalg.eig(L0) # lambda_vals will be 𝜆=𝜎+𝑖𝜔\n# Damping timescale: \ndamping_t=-1/np.real(lambda_vals)\n# Period (if oscillatory): \nperiod=2*np.pi/np.imag(lambda_vals)\n# check for stationary modes and assign period of NaN\nperiod[np.imag(lambda_vals) == 0] = np.nan\n\n# Extract real and imaginary parts\nreal_parts = np.real(lambda_vals)# Eigenvalues of L0 (Real parts)\nimag_parts = np.imag(lambda_vals)# Eigenvalues of L0 (Imaginary parts)\n\n# Stability check\nif np.any(real_parts > 0):\n    print(\"WARNING: System may be unstable (positive eigenvalues detected).\")\nelse:\n    print(\"System is stable (all eigenvalues have non-positive real parts).\")\n    \nprint(\"Damping timescales (months):\", np.round(damping_t, 2))\nprint(\"Period (months):\", np.round(period, 2))\n# Mode 1 & 2 are a conjugate pair (±31.4 months)\n# Mode 3 & 4: another pair (±36.38 months)\n# refer to Lou paper in seminar and their Table 2, where index 2 had 2 modes",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}